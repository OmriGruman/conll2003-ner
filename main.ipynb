{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzvrOf5fKZKy"
   },
   "source": [
    "# Named Entity Recognition: RNN vs Pre-Trained Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKCYvMgxKZKz"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RbCGrBgIKZK0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 23:46:18.577737: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-21 23:46:19.160769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "\n",
    "# GloVe\n",
    "import gensim.downloader\n",
    "\n",
    "# Transformers\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification, TrainingArguments\n",
    "\n",
    "# DL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_sequence, unpack_sequence\n",
    "\n",
    "# Hugging Face\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8QnxHZ4KZK2"
   },
   "source": [
    "## 1 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlBcI2CuKZK2"
   },
   "source": [
    "### 1.1 Data Exploration & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = gensim.downloader.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_embeddings), len(glove_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/home/markkl/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6f938a0043469aa6b72ffcca6ddaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conll2003_dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14041, 3250, 3453]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dataset.num_rows for dataset in conll2003_dataset.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'pos_tags': Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None),\n",
       " 'chunk_tags': Sequence(feature=ClassLabel(names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003_dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = conll2003_dataset['train'][:]['tokens']\n",
    "plt.hist([len(s) for s in sentences], bins=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'O': 0,\n",
       "  'B-PER': 1,\n",
       "  'I-PER': 2,\n",
       "  'B-ORG': 3,\n",
       "  'I-ORG': 4,\n",
       "  'B-LOC': 5,\n",
       "  'I-LOC': 6,\n",
       "  'B-MISC': 7,\n",
       "  'I-MISC': 8},\n",
       " {0: 'O',\n",
       "  1: 'B-PER',\n",
       "  2: 'I-PER',\n",
       "  3: 'B-ORG',\n",
       "  4: 'I-ORG',\n",
       "  5: 'B-LOC',\n",
       "  6: 'I-LOC',\n",
       "  7: 'B-MISC',\n",
       "  8: 'I-MISC'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2id = {tag: i for i, tag in enumerate(conll2003_dataset['train'].features['ner_tags'].feature.names)}\n",
    "id2tag = {i: tag for i, tag in enumerate(conll2003_dataset['train'].features['ner_tags'].feature.names)}\n",
    "\n",
    "tag2id, id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23623\n",
      "9966\n"
     ]
    }
   ],
   "source": [
    "all_tokens = []\n",
    "\n",
    "for sequence in conll2003_dataset['train']:\n",
    "    all_tokens = list(set(all_tokens + sequence['tokens']))\n",
    "    \n",
    "print(len(all_tokens))\n",
    "\n",
    "all_tokens = []\n",
    "\n",
    "for sequence in conll2003_dataset['validation']:\n",
    "    all_tokens = list(set(all_tokens + sequence['tokens']))\n",
    "    \n",
    "print(len(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = -1\n",
    "\n",
    "def get_keys_from_DataSet(DS_NAME, keys = ['tokens','ner_tags']):\n",
    "     return [conll2003_dataset[DS_NAME][:max_len].get(key) for key in keys]\n",
    " \n",
    "\n",
    "# Split data\n",
    "train_data, train_label = get_keys_from_DataSet('train')\n",
    "val_data, val_label= get_keys_from_DataSet('validation')\n",
    "test_data, test_label  = get_keys_from_DataSet('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbOtr-9DKZK6"
   },
   "source": [
    "### 1.2 Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN = '<unk>'\n",
    "\n",
    "vocab = []\n",
    "for line in train_data:\n",
    "  vocab += line\n",
    "vocab+= [UNKNOWN]\n",
    "\n",
    "# Create dictionaries to convert between tokens and indices\n",
    "token_to_index = {tok: i for i, tok in enumerate(set(vocab))}\n",
    "index_to_token = {i: tok for i, tok in enumerate(set(vocab))}\n",
    "\n",
    "def word_to_index(word):\n",
    "    if word in token_to_index:\n",
    "        return token_to_index[word]\n",
    "    return token_to_index[UNKNOWN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelDataset(Dataset):\n",
    "    def __init__(self, data, labels):      \n",
    "        data_as_index = [list(map(word_to_index, sentence)) for sentence in data]  \n",
    "        self.X = data_as_index\n",
    "        self.y = labels\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LanguageModelDataset(train_data, train_label)\n",
    "val_dataset = LanguageModelDataset(val_data, val_label)\n",
    "test_dataset = LanguageModelDataset(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_fn(batch):\n",
    "    padded_batch = pack_sequence([torch.tensor(sample[0], dtype=torch.long) for sample in batch], enforce_sorted=False)\n",
    "    labels = pack_sequence([torch.tensor(sample[1], dtype=torch.long) for sample in batch], enforce_sorted=False)\n",
    "    return padded_batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create a DataLoader object\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=my_collate_fn)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, collate_fn=my_collate_fn)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=my_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'] [3, 0, 7, 0, 0, 0, 7, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0], train_label[0])\n",
    "\n",
    "# # print batch\n",
    "# for sentence, labels in train_dataloader:\n",
    "#     [print(a) for a in zip([[index_to_token[word] for word in token_ind.tolist()] for token_ind in unpack_sequence(sentence)],\n",
    "#           [label.tolist() for label in unpack_sequence(labels)])]\n",
    "#     break\n",
    "\n",
    "# print('\\n')\n",
    "\n",
    "# #print whole data\n",
    "# for sentence, labels in train_dataloader:\n",
    "#     [print(a) for a in zip([[index_to_token[word] for word in token_ind.tolist()] for token_ind in unpack_sequence(sentence)],\n",
    "#           [label.tolist() for label in unpack_sequence(labels)])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd9NW6F4KZK7"
   },
   "source": [
    "### 1.3 Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxcX4EVWw6C6"
   },
   "source": [
    "#### 1.3.1 Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, num_layers = 3,embedding_dim = 300,dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 =  nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input_sequence):\n",
    "        \n",
    "        # Unpack the input sequence into individual tokens\n",
    "        unpacked_sequence = unpack_sequence(input_sequence)\n",
    "\n",
    "        # Execute a forward pass of the LSTMModel\n",
    "        batch_size = len(unpacked_sequence)\n",
    "        \n",
    "        # Convert each token into an embedding vector\n",
    "        embedded_sequence = [torch.tensor(np.array([self.use_glove(index_to_token[word]) for word in token.tolist()]), dtype=torch.float).cuda() for token in unpacked_sequence]\n",
    "        \n",
    "        # Pack the embedded sequence for variable length support\n",
    "        packed_sequence = pack_sequence(embedded_sequence, enforce_sorted=False)\n",
    "        # Pass the packed sequence through the LSTM layer\n",
    "        lstm_output, (hidden_state, cell_state) = self.lstm(packed_sequence)\n",
    " \n",
    "        # Apply dropout to the LSTM output\n",
    "        unpacked_output = unpack_sequence(lstm_output)\n",
    "        lstm_output_dropout = [self.dropout(tensor) for tensor in unpacked_output]\n",
    "\n",
    "        output = []\n",
    "        # unpack the LSTM output and pass it through the linear layer\n",
    "        for a in unpack_sequence(lstm_output):\n",
    "            output.append(self.fc2(self.relu(self.fc1(a))))\n",
    "            \n",
    "        # Return the final output\n",
    "        return output # torch.stack(output)\n",
    "      \n",
    "    def use_glove(self, word):\n",
    "     if word in glove_embeddings:\n",
    "          return glove_embeddings[word]\n",
    "     else:\n",
    "          return np.zeros((300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_into_onehot(labels):\n",
    "    res = []\n",
    "    for label in labels:\n",
    "        onehot = np.zeros(len(tag2id),dtype=np.float64)\n",
    "        onehot[label] = 1.0\n",
    "        res.append(torch.tensor(onehot,dtype=torch.float))\n",
    "    return torch.stack(res)\n",
    "\n",
    "def batch_into_onehot(batch):\n",
    "    return torch.cat([labels_into_onehot(labels).clone().detach() for labels in batch]).cuda()#torch.stack([labels_into_onehot(labels) for labels in batch]).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CsPUE1pw6C7"
   },
   "source": [
    "#### 1.3.2 Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.8498, Val Loss: 0.5292, Perplexity: 1.6975\n",
      "Epoch 2/100, Train Loss: 0.4552, Val Loss: 0.4225, Perplexity: 1.5258\n",
      "Epoch 3/100, Train Loss: 0.3591, Val Loss: 0.3778, Perplexity: 1.4590\n",
      "Epoch 4/100, Train Loss: 0.3212, Val Loss: 0.3713, Perplexity: 1.4496\n",
      "Epoch 5/100, Train Loss: 0.2953, Val Loss: 0.3360, Perplexity: 1.3994\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 87\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# # Create the model and train it\u001b[39;00m\n\u001b[1;32m     84\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMModel(tag_vocab_size,  hidden_dim)\n\u001b[0;32m---> 87\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, lr, num_epochs, patience)\u001b[0m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     29\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m---> 31\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(torch\u001b[38;5;241m.\u001b[39mcat(outputs), \u001b[43mbatch_into_onehot\u001b[49m\u001b[43m(\u001b[49m\u001b[43munpack_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization step\u001b[39;00m\n\u001b[1;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m, in \u001b[0;36mbatch_into_onehot\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_into_onehot\u001b[39m(batch):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([labels_into_onehot(labels)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m labels \u001b[38;5;129;01min\u001b[39;00m batch])\u001b[38;5;241m.\u001b[39mcuda()\n",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_into_onehot\u001b[39m(batch):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mlabels_into_onehot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m labels \u001b[38;5;129;01min\u001b[39;00m batch])\u001b[38;5;241m.\u001b[39mcuda()\n",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m, in \u001b[0;36mlabels_into_onehot\u001b[0;34m(labels)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[1;32m      4\u001b[0m     onehot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(tag2id),dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m----> 5\u001b[0m     onehot[label] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m      6\u001b[0m     res\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(onehot,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(res)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "def train(model, lr=0.0001, num_epochs=100,patience=6):\n",
    "    patience_counter = 0\n",
    "    best_loss = -1\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    loss = None\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "      train_loss = 0.0\n",
    "      val_loss = 0.0\n",
    "\n",
    "      model.train()\n",
    "      for inputs, targets in train_dataloader:\n",
    "\n",
    "          inputs = inputs.to(device)\n",
    "          targets = targets.to(device)\n",
    "          \n",
    "          # Zero the gradients and forward pass\n",
    "          model.zero_grad()\n",
    "          \n",
    "          outputs = model(inputs)\n",
    "        \n",
    "          loss = criterion(torch.cat(outputs), batch_into_onehot(unpack_sequence(targets)))\n",
    "\n",
    "          # Backward pass and optimization step\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          train_loss += loss.item()\n",
    "          \n",
    "      # Validation\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "\n",
    "        for inputs, targets in val_dataloader:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Zero the gradients and forward pass\n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(torch.cat(outputs), batch_into_onehot(unpack_sequence(targets)))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "        \n",
    "        # Calculate average losses\n",
    "        train_loss /= len(train_dataloader)\n",
    "        val_loss /= len(val_dataloader)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Perplexity: {np.exp(val_loss):.4f}')\n",
    "        \n",
    "        # Check if validation loss is increasing, and break the loop if it is\n",
    "        if  epoch > 0 and val_losses[-1] >= best_loss:\n",
    "            patience_counter+=1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Best Epoch number {epoch-patience+1} :: Val Loss: {best_loss:.4f}, Perplexity: {np.exp(best_loss):.4f}')\n",
    "                return best_model\n",
    "        else:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            \n",
    "            patience_counter = 0\n",
    "            best_loss = val_losses[-1]\n",
    "            \n",
    "    return best_model            \n",
    "            \n",
    "tag_vocab_size = len(tag2id)\n",
    "hidden_dim = 100\n",
    "\n",
    "# # Create the model and train it\n",
    "model = LSTMModel(tag_vocab_size,  hidden_dim)\n",
    "\n",
    "\n",
    "model = train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8867310428072596\n"
     ]
    }
   ],
   "source": [
    "model.lstm.flatten_parameters()\n",
    "model.eval()\n",
    "count = 0\n",
    "i = 0\n",
    "for inputs, targets in test_dataloader:\n",
    "\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      # Zero the gradients and forward pass\n",
    "      model.zero_grad()\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      for c,e in enumerate(outputs):\n",
    "          tst = nn.Softmax(dim=1)(e)\n",
    "          o = torch.argmax(torch.where(tst>0.42, tst, 0), axis=1)\n",
    "          u = unpack_sequence(targets)[c]\n",
    "          count += torch.sum(u==o).item()\n",
    "          i+=u.size().numel()\n",
    "print(count/i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3Im7yxEKZLP"
   },
   "source": [
    "## 2 Pre-Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/home/markkl/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8563bf51a964219909ca08dd09b9723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conll2003_dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 7: 'B-MISC',\n",
       " 8: 'I-MISC'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = conll2003_dataset[\"train\"].features[f\"ner_tags\"].feature.names\n",
    "id2tag = {id: tag for id, tag in enumerate(label_list)}\n",
    "id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_len = 1000\n",
    "\n",
    "train_dataset = conll2003_dataset[\"train\"].select(range(data_len))\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8m7k9U5KZLP"
   },
   "source": [
    "### 2.1 Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer(conll2003_dataset[\"train\"][2][\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/markkl/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-0406a691f1b72d72.arrow\n",
      "Loading cached processed dataset at /home/markkl/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-ef7bd1f5d4137b64.arrow\n",
      "Loading cached processed dataset at /home/markkl/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-1c4e3111aac637e4.arrow\n",
      "Loading cached processed dataset at /home/markkl/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-3e54e5f831c47244.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_conll2003 = conll2003_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_labels</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brussels</td>\n",
       "      <td>5</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tokens  ner_labels ner_tags\n",
       "0     [CLS]        -100   ignore\n",
       "1  brussels           5    B-LOC\n",
       "2      1996           0        O\n",
       "3         -        -100   ignore\n",
       "4        08        -100   ignore\n",
       "5         -        -100   ignore\n",
       "6        22        -100   ignore\n",
       "7     [SEP]        -100   ignore"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2tag[-100]='ignore'\n",
    "exml=tokenized_train_dataset[2]\n",
    "\n",
    "pd.DataFrame({'tokens':tokenizer.convert_ids_to_tokens(exml[\"input_ids\"]), 'ner_labels':exml['labels'], 'ner_tags': [id2tag[label] for label in exml['labels']] })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZExQ5fZuq1d"
   },
   "source": [
    "### 2.2 Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Data Collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_seqeval = evaluate.load(\"seqeval\")\n",
    "example = conll2003_dataset[\"train\"][2]\n",
    "\n",
    "labels = [label_list[i] for i in example[\"ner_tags\"]]\n",
    "metric_seqeval.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric_seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markkl/.conda/envs/tf_gpu/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [315/315 00:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.684403</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>0.021205</td>\n",
       "      <td>0.020768</td>\n",
       "      <td>0.728340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.608373</td>\n",
       "      <td>0.361277</td>\n",
       "      <td>0.030461</td>\n",
       "      <td>0.056185</td>\n",
       "      <td>0.842218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289739</td>\n",
       "      <td>0.540595</td>\n",
       "      <td>0.587176</td>\n",
       "      <td>0.562924</td>\n",
       "      <td>0.924399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.193698</td>\n",
       "      <td>0.629037</td>\n",
       "      <td>0.708011</td>\n",
       "      <td>0.666192</td>\n",
       "      <td>0.946264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144892</td>\n",
       "      <td>0.734738</td>\n",
       "      <td>0.798048</td>\n",
       "      <td>0.765086</td>\n",
       "      <td>0.961489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markkl/.local/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=315, training_loss=0.7791654556516617, metrics={'train_runtime': 34.3067, 'train_samples_per_second': 145.744, 'train_steps_per_second': 9.182, 'total_flos': 109081967876928.0, 'train_loss': 0.7791654556516617, 'epoch': 5.0})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./log_results',\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,   \n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500, \n",
    "    eval_steps=60,\n",
    "    save_steps=60,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_conll2003[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 6)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAcdz9yYKZLS",
    "tags": []
   },
   "source": [
    "#### 2.3 Comparison to RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.7112831858407079,\n",
       "  'recall': 0.7709832134292566,\n",
       "  'f1': 0.7399309551208285,\n",
       "  'number': 1668},\n",
       " 'MISC': {'precision': 0.4727932285368803,\n",
       "  'recall': 0.5569800569800569,\n",
       "  'f1': 0.5114453891432308,\n",
       "  'number': 702},\n",
       " 'ORG': {'precision': 0.6281329923273657,\n",
       "  'recall': 0.7393136664659844,\n",
       "  'f1': 0.6792035398230089,\n",
       "  'number': 1661},\n",
       " 'PER': {'precision': 0.9367959949937422,\n",
       "  'recall': 0.9257884972170687,\n",
       "  'f1': 0.9312597200622086,\n",
       "  'number': 1617},\n",
       " 'overall_precision': 0.711376858435682,\n",
       " 'overall_recall': 0.7793909348441926,\n",
       " 'overall_f1': 0.7438323758026361,\n",
       " 'overall_accuracy': 0.9560891568859696}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_conll2003[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric_seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.3.1 Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.3.2 Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.3.3 Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Conclusions"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
