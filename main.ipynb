{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lzvrOf5fKZKy"
      },
      "source": [
        "# Named Entity Recognition: RNN vs Pre-Trained Transformer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SKCYvMgxKZKz"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "RbCGrBgIKZK0"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# GloVe\n",
        "import gensim.downloader\n",
        "\n",
        "# DL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_sequence, unpack_sequence\n",
        "\n",
        "# Hugging Face\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a8QnxHZ4KZK2"
      },
      "source": [
        "## 1 RNN"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UlBcI2CuKZK2"
      },
      "source": [
        "### 1.1 Data Exploration & Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [],
      "source": [
        "glove_embeddings = gensim.downloader.load(\"glove-wiki-gigaword-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 300)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(glove_embeddings), len(glove_embeddings[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset conll2003 (C:/Users/markk/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
            "100%|██████████| 3/3 [00:00<00:00, 296.10it/s]\n"
          ]
        }
      ],
      "source": [
        "conll2003_dataset = load_dataset(\"conll2003\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[14041, 3250, 3453]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[dataset.num_rows for dataset in conll2003_dataset.values()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': Value(dtype='string', id=None),\n",
              " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'pos_tags': Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None),\n",
              " 'chunk_tags': Sequence(feature=ClassLabel(names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None),\n",
              " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conll2003_dataset['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sentences = conll2003_dataset['train'][:]['tokens']\n",
        "plt.hist([len(s) for s in sentences], bins=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'O': 0,\n",
              "  'B-PER': 1,\n",
              "  'I-PER': 2,\n",
              "  'B-ORG': 3,\n",
              "  'I-ORG': 4,\n",
              "  'B-LOC': 5,\n",
              "  'I-LOC': 6,\n",
              "  'B-MISC': 7,\n",
              "  'I-MISC': 8},\n",
              " {0: 'O',\n",
              "  1: 'B-PER',\n",
              "  2: 'I-PER',\n",
              "  3: 'B-ORG',\n",
              "  4: 'I-ORG',\n",
              "  5: 'B-LOC',\n",
              "  6: 'I-LOC',\n",
              "  7: 'B-MISC',\n",
              "  8: 'I-MISC'})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tag2id = {tag: i for i, tag in enumerate(conll2003_dataset['train'].features['ner_tags'].feature.names)}\n",
        "id2tag = {i: tag for i, tag in enumerate(conll2003_dataset['train'].features['ner_tags'].feature.names)}\n",
        "\n",
        "tag2id, id2tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23623\n",
            "9966\n"
          ]
        }
      ],
      "source": [
        "all_tokens = []\n",
        "\n",
        "for sequence in conll2003_dataset['train']:\n",
        "    all_tokens = list(set(all_tokens + sequence['tokens']))\n",
        "    \n",
        "print(len(all_tokens))\n",
        "\n",
        "all_tokens = []\n",
        "\n",
        "for sequence in conll2003_dataset['validation']:\n",
        "    all_tokens = list(set(all_tokens + sequence['tokens']))\n",
        "    \n",
        "print(len(all_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_len = 4\n",
        "\n",
        "def get_keys_from_DataSet(DS_NAME, keys = ['tokens','ner_tags']):\n",
        "     return [conll2003_dataset[DS_NAME][:max_len].get(key) for key in keys]\n",
        " \n",
        "\n",
        "# Split data\n",
        "train_data, train_label = get_keys_from_DataSet('train')\n",
        "val_data, val_label= get_keys_from_DataSet('validation')\n",
        "test_data, test_label  = get_keys_from_DataSet('test')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HbOtr-9DKZK6"
      },
      "source": [
        "### 1.2 Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [],
      "source": [
        "UNKNOWN = '<unk>'\n",
        "\n",
        "vocab = []\n",
        "for line in train_data:\n",
        "  vocab += line\n",
        "vocab+= [UNKNOWN]\n",
        "\n",
        "# Create dictionaries to convert between tokens and indices\n",
        "token_to_index = {tok: i for i, tok in enumerate(set(vocab))}\n",
        "index_to_token = {i: tok for i, tok in enumerate(set(vocab))}\n",
        "\n",
        "def word_to_index(word):\n",
        "    if word in token_to_index:\n",
        "        return token_to_index[word]\n",
        "    return token_to_index[UNKNOWN]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LanguageModelDataset(Dataset):\n",
        "    def __init__(self, data, labels):      \n",
        "        data_as_index = [list(map(word_to_index, sentence)) for sentence in data]  \n",
        "        self.X = data_as_index\n",
        "        self.y = labels\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.y[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = LanguageModelDataset(train_data, train_label)\n",
        "val_dataset = LanguageModelDataset(val_data, val_label)\n",
        "test_dataset = LanguageModelDataset(test_data, test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_collate_fn(batch):\n",
        "    padded_batch = pack_sequence([torch.tensor(sample[0], dtype=torch.long) for sample in batch], enforce_sorted=False)\n",
        "    labels = pack_sequence([torch.tensor(sample[1], dtype=torch.long) for sample in batch], enforce_sorted=False)\n",
        "    return padded_batch, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 1\n",
        "\n",
        "# Create a DataLoader object\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=my_collate_fn)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, collate_fn=my_collate_fn)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=my_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'] [3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
            "\n",
            "(['BRUSSELS', '1996-08-22'], [5, 0])\n",
            "\n",
            "\n",
            "(['BRUSSELS', '1996-08-22'], [5, 0])\n",
            "(['The', 'European', 'Commission', 'said', 'on', 'Thursday', 'it', 'disagreed', 'with', 'German', 'advice', 'to', 'consumers', 'to', 'shun', 'British', 'lamb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.'], [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "(['Peter', 'Blackburn'], [1, 2])\n",
            "(['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], [3, 0, 7, 0, 0, 0, 7, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "print(train_data[0], train_label[0])\n",
        "print()\n",
        "\n",
        "# print batch\n",
        "for sentence, labels in train_dataloader:\n",
        "    [print(a) for a in zip([[index_to_token[word] for word in token_ind.tolist()] for token_ind in unpack_sequence(sentence)],\n",
        "          [label.tolist() for label in unpack_sequence(labels)])]\n",
        "    break\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "#print whole data\n",
        "for sentence, labels in train_dataloader:\n",
        "    [print(a) for a in zip([[index_to_token[word] for word in token_ind.tolist()] for token_ind in unpack_sequence(sentence)],\n",
        "          [label.tolist() for label in unpack_sequence(labels)])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 300])\n",
            "torch.Size([30, 300])\n",
            "torch.Size([9, 300])\n",
            "torch.Size([2, 300])\n"
          ]
        }
      ],
      "source": [
        "def use_glove(word):\n",
        "     if word in glove_embeddings:\n",
        "          return glove_embeddings[word]\n",
        "     else:\n",
        "          return np.zeros((300))\n",
        "\n",
        "for sentence, labels in train_dataloader:\n",
        "     unpacked_sequence= unpack_sequence(sentence)\n",
        "     a = [torch.tensor([use_glove(index_to_token[word]) for word in token.tolist()]) for token in unpacked_sequence]\n",
        "     b= pack_sequence(a)\n",
        "     print(b.data.size())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qd9NW6F4KZK7"
      },
      "source": [
        "### 1.3 Model "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zxcX4EVWw6C6"
      },
      "source": [
        "#### 1.3.1 Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_dim, num_layers = 1,embedding_dim = 300):\n",
        "        super().__init__()\n",
        "        self.embedding = glove_embeddings\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers,bidirectional=True)\n",
        "        self.fc = nn.Linear(2*hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input_sequence):\n",
        "        \n",
        "        # Unpack the input sequence into individual tokens\n",
        "        unpacked_sequence = unpack_sequence(input_sequence)\n",
        "\n",
        "        # Execute a forward pass of the LSTMModel\n",
        "        batch_size = len(unpacked_sequence)\n",
        "        \n",
        "        # Convert each token into an embedding vector\n",
        "        embedded_sequence = [torch.tensor([use_glove(index_to_token[word]) for word in token.tolist()]) for token in unpacked_sequence]\n",
        "        \n",
        "        # Pack the embedded sequence for variable length support\n",
        "        packed_sequence = pack_sequence(embedded_sequence, enforce_sorted=False)\n",
        "        print(3)\n",
        "        # Pass the packed sequence through the LSTM layer\n",
        "        lstm_output, (hidden_state, cell_state) = self.lstm(packed_sequence)\n",
        "        print(4)\n",
        "        \n",
        "        output = []\n",
        "        # Reshape the LSTM output and pass it through the linear layer\n",
        "        for out in lstm_output:\n",
        "            output.append = self.fc(out.reshape(batch_size, -1))\n",
        "        print(5)\n",
        "        # Return the final output\n",
        "        return output\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-CsPUE1pw6C7"
      },
      "source": [
        "#### 1.3.2 Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "only one element tensors can be converted to Python scalars",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[347], line 76\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m# Create the model and train it\u001b[39;00m\n\u001b[0;32m     73\u001b[0m model \u001b[39m=\u001b[39m LSTMModel(vocab_size,  hidden_dim)\n\u001b[1;32m---> 76\u001b[0m train(model)\n",
            "Cell \u001b[1;32mIn[347], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, lr, num_epochs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m# Zero the gradients and forward pass\u001b[39;00m\n\u001b[0;32m     24\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 27\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     28\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     30\u001b[0m \u001b[39m# Backward pass and optimization step\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\markk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[1;32mIn[346], line 23\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, input_sequence)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m3\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[39m# Pass the packed sequence through the LSTM layer\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m lstm_output, (hidden_state, cell_state) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(torch\u001b[39m.\u001b[39;49mtensor(embedded_sequence))\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m4\u001b[39m)\n\u001b[0;32m     26\u001b[0m output \u001b[39m=\u001b[39m []\n",
            "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "def train(model, lr=0.0001, num_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "    loss = None\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(num_epochs):\n",
        "      train_loss = 0.0\n",
        "      val_loss = 0.0\n",
        "\n",
        "      model.train()\n",
        "      for inputs, targets in train_dataloader:\n",
        "\n",
        "          inputs = inputs.to(device)\n",
        "          targets = targets.to(device)\n",
        "          \n",
        "          # Zero the gradients and forward pass\n",
        "          model.zero_grad()\n",
        "\n",
        "        \n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, targets)\n",
        "          \n",
        "          # Backward pass and optimization step\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_loss += loss.item()\n",
        "          \n",
        "      # Validation\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "\n",
        "        for inputs, targets in val_dataloader:\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Zero the gradients and forward pass\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "        \n",
        "        # Calculate average losses\n",
        "        train_loss /= len(train_dataloader)\n",
        "        val_loss /= len(val_dataloader)\n",
        "\n",
        "        # Save losses\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "        \n",
        "        # Check if validation loss is increasing, and break the loop if it is\n",
        "        if  epoch > 1 and val_losses[-1] >= val_losses[-2] and val_losses[-2] >= val_losses[-3]:\n",
        "            break\n",
        "            \n",
        "vocab_size = len(token_to_index)\n",
        "embedding_dim = 40\n",
        "hidden_dim = 40\n",
        "num_layers = 3\n",
        "\n",
        "# Create the model and train it\n",
        "model = LSTMModel(vocab_size,  hidden_dim)\n",
        "\n",
        "\n",
        "train(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.3.3 Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Im7yxEKZLP"
      },
      "source": [
        "## 2 Pre-Trained Transformer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t8m7k9U5KZLP"
      },
      "source": [
        "### 2.1 Dataset & Dataloader"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EZExQ5fZuq1d"
      },
      "source": [
        "### 2.2 Fine-Tuning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bAcdz9yYKZLS"
      },
      "source": [
        "#### 2.3 Comparison to RNN"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3.1 Setups"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3.2 Approaches"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3.3 Error Analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 Conclusions"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
